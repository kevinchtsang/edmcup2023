{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53ad5b39",
   "metadata": {
    "papermill": {
     "duration": 0.003469,
     "end_time": "2023-03-30T14:17:17.647730",
     "exception": false,
     "start_time": "2023-03-30T14:17:17.644261",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# In this example notebook, the quantity and frequency of actions taken by a student in the past is used to predict their score on every problem within their unit test. This method does not take into account the differences between problems, which is not a good idea, and therefore makes the same prediction for every problem within a students' unit test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "216c4ad6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T14:17:17.654601Z",
     "iopub.status.busy": "2023-03-30T14:17:17.654177Z",
     "iopub.status.idle": "2023-03-30T14:17:19.039151Z",
     "shell.execute_reply": "2023-03-30T14:17:19.037682Z"
    },
    "papermill": {
     "duration": 1.392148,
     "end_time": "2023-03-30T14:17:19.042548",
     "exception": false,
     "start_time": "2023-03-30T14:17:17.650400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c77461a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T14:17:19.053782Z",
     "iopub.status.busy": "2023-03-30T14:17:19.052995Z",
     "iopub.status.idle": "2023-03-30T14:18:01.468552Z",
     "shell.execute_reply": "2023-03-30T14:18:01.467249Z"
    },
    "papermill": {
     "duration": 42.424147,
     "end_time": "2023-03-30T14:18:01.471787",
     "exception": false,
     "start_time": "2023-03-30T14:17:19.047640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the necessary data\n",
    "\n",
    "tuts = pd.read_csv('/kaggle/input/edm-cup-2023/training_unit_test_scores.csv')\n",
    "euts = pd.read_csv('/kaggle/input/edm-cup-2023/evaluation_unit_test_scores.csv')\n",
    "ar = pd.read_csv('/kaggle/input/edm-cup-2023/assignment_relationships.csv')\n",
    "al = pd.read_csv('/kaggle/input/edm-cup-2023/action_logs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57abc749",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T14:18:01.478976Z",
     "iopub.status.busy": "2023-03-30T14:18:01.478548Z",
     "iopub.status.idle": "2023-03-30T14:18:49.041124Z",
     "shell.execute_reply": "2023-03-30T14:18:49.039316Z"
    },
    "papermill": {
     "duration": 47.570013,
     "end_time": "2023-03-30T14:18:49.044434",
     "exception": false,
     "start_time": "2023-03-30T14:18:01.474421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Associate the action logs for each in unit assignment with their unit test assignment\n",
    "df = ar.merge(al, how='left', left_on='in_unit_assignment_log_id', right_on='assignment_log_id')\n",
    "df = df[['unit_test_assignment_log_id', 'action']]\n",
    "\n",
    "# Get the total number of times each action was taken within the in unit assignments corresponding to each unit test assignment\n",
    "df = pd.get_dummies(df, columns=['action'])\n",
    "df = df.groupby('unit_test_assignment_log_id').sum()\n",
    "\n",
    "# Create a feature for the total action count, then scale it between 0 and 1\n",
    "action_count = df.sum(axis=1)\n",
    "\n",
    "# Convert the individual action counts into a fraction of total actions taken\n",
    "df = df.div(action_count, axis=0)\n",
    "\n",
    "# Add the scaled total action count to the dataframe\n",
    "df['action_count'] = (action_count - action_count.min()) / (action_count.max() - action_count.min())\n",
    "\n",
    "# Merge action count features with the training unit test scores\n",
    "tuts = tuts.merge(df, how='left', left_on='assignment_log_id', right_index=True)\n",
    "\n",
    "# Merge action count features with the evaluation unit test scores\n",
    "euts = euts.merge(df, how='left', left_on='assignment_log_id', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b15be76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T14:18:49.052171Z",
     "iopub.status.busy": "2023-03-30T14:18:49.051698Z",
     "iopub.status.idle": "2023-03-30T14:19:04.272517Z",
     "shell.execute_reply": "2023-03-30T14:19:04.270908Z"
    },
    "papermill": {
     "duration": 15.228066,
     "end_time": "2023-03-30T14:19:04.275621",
     "exception": false,
     "start_time": "2023-03-30T14:18:49.047555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Collect the input and target columns for the regression\n",
    "input_cols = [c for c in tuts.columns if 'action' in c]\n",
    "target_col = 'score'\n",
    "\n",
    "# Initialize a logistic regression\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "# Fit the regression on all the training data\n",
    "lr = lr.fit(tuts[input_cols], tuts[target_col])\n",
    "# Predict the score for each evaluation problem\n",
    "euts[target_col] = lr.predict_proba(euts[input_cols])[:,1]\n",
    "\n",
    "# Export the id and score columns of the evaluation unit test scores file for uploading to Kaggle\n",
    "euts[['id', 'score']].to_csv('/kaggle/working/example_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda38153",
   "metadata": {
    "papermill": {
     "duration": 0.00224,
     "end_time": "2023-03-30T14:19:04.280545",
     "exception": false,
     "start_time": "2023-03-30T14:19:04.278305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 119.431313,
   "end_time": "2023-03-30T14:19:05.813339",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-30T14:17:06.382026",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
